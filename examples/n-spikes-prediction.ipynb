{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cfde87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('/Users/leongugel/PycharmProjects/spectral-phase-retrieval')\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, rfft, irfft, ifft,fftshift, fft2, ifft2, dct, idct\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from PIL import Image, ImageCms\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from models.seq_blocks import MlpNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559363d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b9aabb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_magitude(img, shift: bool=True):\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img_tensor = torch.from_numpy(img)\n",
    "    else:\n",
    "        img_tensor = img\n",
    "    fft_img = torch.fft.fft2(img_tensor, norm=\"forward\")\n",
    "    fft_img_magnitude = torch.abs(fft_img)\n",
    "    if shift:\n",
    "        fft_img_magnitude = torch.fft.fftshift(fft_img_magnitude)\n",
    "    return fft_img_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6dc2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pol2cart(r, phi):\n",
    "    x = r * np.cos(phi)\n",
    "    y = r * np.sin(phi)\n",
    "    return(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd95141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_spike_signals_polar(n_spikes: int = 1, \n",
    "                                   img_size: int = 32, \n",
    "                                   min_dist: int = 4, \n",
    "                                   sigma: float = 1.0, \n",
    "                                   add_gauss_noise: float = 0.0125) -> torch.Tensor:\n",
    "    phi_ranges = 2*np.pi*np.arange(0, n_spikes, 1)/n_spikes\n",
    "    half_size = img_size // 2\n",
    "    r_ranges =( np.random.permutation(half_size-2*min_dist)+min_dist)[:n_spikes]\n",
    "    x, y = pol2cart(r_ranges, phi_ranges)\n",
    "    x += (half_size)\n",
    "    y += (half_size)\n",
    "    x = np.int32(np.round(x))\n",
    "    y = np.int32(np.round(y))\n",
    "    img_spikes = np.zeros((img_size, img_size))\n",
    "    for ind in range(n_spikes):\n",
    "        img_spikes[y[ind], x[ind]] =1.0\n",
    "    if sigma > 0: \n",
    "        img_spikes = gaussian_filter(img_spikes, sigma)\n",
    "    img_spikes = torch.from_numpy(img_spikes)\n",
    "    if add_gauss_noise > 0.0:\n",
    "        img_spikes = img_spikes + add_gauss_noise*torch.randn_like(img_spikes)\n",
    "    \n",
    "    return img_spikes, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16ed54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpikesSampler(Sampler):\n",
    "    def __init__(self,\n",
    "                 batch_size: int = 4,\n",
    "                 spikes_range=(3, 16),\n",
    "                 img_size: int = 32,\n",
    "                 min_dist: int = 4,\n",
    "                 sigma: float = 1.0,\n",
    "                 add_gauss_noise: float = 0.0125,\n",
    "                 len_ds: int = 10000):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.spikes_range = spikes_range\n",
    "        self.img_size = img_size\n",
    "        self.min_dist = min_dist\n",
    "        self.sigma = sigma\n",
    "        self.add_gauss_noise = add_gauss_noise\n",
    "        self.len_ds = len_ds\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        raise int(self.len_ds)\n",
    "\n",
    "    def _get_item(self):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        n_spikes = np.random.randint(self.spikes_range[0], self.spikes_range[1])\n",
    "\n",
    "        # Load data and get label\n",
    "        # print(f'n_spikes:{n_spikes}, self.img_size: {self.img_size}')\n",
    "        img_spikes, x, y = get_random_spike_signals_polar(n_spikes=n_spikes,\n",
    "                                                          img_size=self.img_size,\n",
    "                                                          min_dist=self.min_dist,\n",
    "                                                          sigma=self.sigma,\n",
    "                                                          add_gauss_noise=self.add_gauss_noise)\n",
    "        fft_spkes = fft_magitude(img_spikes)\n",
    "\n",
    "        return fft_spkes, img_spikes, n_spikes, x, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch = {'fft_spikes': [], 'img_spikes': [], 'n_spikes': [], 'x': [], 'y': []}\n",
    "        for _ in range(self.batch_size):\n",
    "            fft_spkes, img_spikes, n_spikes, x, y = self._get_item()\n",
    "            batch['fft_spikes'].append(fft_spkes)\n",
    "            batch['img_spikes'].append(img_spikes)\n",
    "            batch['n_spikes'].append(n_spikes)\n",
    "            batch['x'].append(x)\n",
    "            batch['y'].append(y)\n",
    "        batch['fft_spikes'] = torch.stack(batch['fft_spikes'])\n",
    "        batch['n_spikes'] = torch.tensor(batch['n_spikes'])[:, None]\n",
    "        yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1765d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                 spikes_range = [3, 16],\n",
    "                 img_size: int = 32, \n",
    "                 min_dist: int = 4, \n",
    "                 sigma: float = 1.0, \n",
    "                 add_gauss_noise: float = 0.0125,\n",
    "                  len_ds: int = 10000):\n",
    "        'Initialization'\n",
    "        self.spikes_range=spikes_range\n",
    "        self.img_size = img_size\n",
    "        self.min_dist = min_dist\n",
    "        self.sigma = sigma\n",
    "        self.add_gauss_noise = add_gauss_noise \n",
    "        self.len_ds =len_ds\n",
    "\n",
    "    def __len__(self):\n",
    "            'Denotes the total number of samples'\n",
    "            raise int(self.len_ds)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            'Generates one sample of data'\n",
    "            # Select sample\n",
    "            n_spikes = np.random.randint(spikes_range[0],spikes_range[1])\n",
    "\n",
    "            # Load data and get label\n",
    "            img_spikes, x, y = get_random_spike_signals_polar(n_spikes=n_spikes, \n",
    "                                   img_size = self.img_size, \n",
    "                                   min_dist = self.min_dist, \n",
    "                                   sigma =  self.sigma, \n",
    "                                   add_gauss_noise = self.add_gauss_noise)\n",
    "            fft_spkes = fft_magitude(img_spikes)\n",
    "\n",
    "            return fft_spkes, img_spikes, n_spikes, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97c3af6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0756c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 8,\n",
    "          'num_workers': 4}\n",
    "spikes_ds = SpikesDataset(len_ds = 10)\n",
    "training_generator = torch.utils.data.DataLoader(spikes_ds, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f9178ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 32\n",
    "batch_size = 16\n",
    "spikes_range=(2, 8)\n",
    "n_classes = spikes_range[1] - spikes_range[0] +1\n",
    "spike_sampler = SpikesSampler(spikes_range=spikes_range, \n",
    "                              img_size=img_size,\n",
    "                              batch_size=batch_size, \n",
    "                              add_gauss_noise = 0.0)\n",
    "batch_spikes_data = next(iter(spike_sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "de87a190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "281abd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = img_size**2\n",
    "ch_list = [in_size, in_size // 4, in_size // 16, in_size // 32, in_size // 128, in_size // 256, 1]\n",
    "mlp_net = MlpNet(in_ch=in_size,\n",
    "                 ch_list = ch_list,\n",
    "                  out_ch=1,\n",
    "                 deep=len(ch_list),\n",
    "                  multy_coeff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb5fee2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpNet(\n",
       "  (fc_layers): BlockList(\n",
       "    (0): FcBlock(\n",
       "      (fc_seq): BlockList(\n",
       "        (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (1): Identity()\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): FcBlock(\n",
       "      (fc_seq): BlockList(\n",
       "        (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (1): Identity()\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): FcBlock(\n",
       "      (fc_seq): BlockList(\n",
       "        (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (1): Identity()\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): FcBlock(\n",
       "      (fc_seq): BlockList(\n",
       "        (0): Linear(in_features=32, out_features=8, bias=True)\n",
       "        (1): Identity()\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): FcBlock(\n",
       "      (fc_seq): BlockList(\n",
       "        (0): Linear(in_features=8, out_features=4, bias=True)\n",
       "        (1): Identity()\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): FcBlock(\n",
       "      (fc_seq): BlockList(\n",
       "        (0): Linear(in_features=4, out_features=1, bias=True)\n",
       "        (1): Identity()\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5366b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 10000\n",
    "mlp_net.train()\n",
    "l2_loss = torch.nn.MSELoss()\n",
    "class_loss = torch.nn.CrossEntropyLoss\n",
    "optim = torch.optim.Adam(params=mlp_net.parameters(), lr= 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feeccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.flatten(batch_spikes_data['fft_spikes'], 1).to(torch.float)\n",
    "y = batch_spikes_data['n_spikes'].to(torch.float)\n",
    "y_pred = mlp_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a714a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.],\n",
       "        [4.],\n",
       "        [7.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [6.],\n",
       "        [5.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [4.],\n",
       "        [6.],\n",
       "        [3.],\n",
       "        [3.],\n",
       "        [6.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b6e77c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.6327],\n",
       "        [3.6515],\n",
       "        [7.6117],\n",
       "        [2.8587],\n",
       "        [0.8750],\n",
       "        [1.4614],\n",
       "        [6.2523],\n",
       "        [5.1917],\n",
       "        [5.3948],\n",
       "        [6.1696],\n",
       "        [3.5093],\n",
       "        [6.3213],\n",
       "        [2.9187],\n",
       "        [2.7440],\n",
       "        [6.5029],\n",
       "        [2.8569]], grad_fn=<LeakyReluBackward1>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8688ab18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind: 0, loss: 3.7030858993530273\n",
      "ind: 500, loss: 3.004824638366699\n",
      "ind: 1000, loss: 3.096035957336426\n",
      "ind: 1500, loss: 2.843257427215576\n",
      "ind: 2000, loss: 1.5155291557312012\n",
      "ind: 2500, loss: 1.6146228313446045\n",
      "ind: 3000, loss: 1.7886306047439575\n",
      "ind: 3500, loss: 1.6603196859359741\n",
      "ind: 4000, loss: 2.0471994876861572\n",
      "ind: 4500, loss: 1.7338281869888306\n",
      "ind: 5000, loss: 0.8767526149749756\n",
      "ind: 5500, loss: 1.363584041595459\n",
      "ind: 6000, loss: 0.6734015941619873\n",
      "ind: 6500, loss: 0.8365642428398132\n",
      "ind: 7000, loss: 0.5023687481880188\n",
      "ind: 7500, loss: 0.25611451268196106\n",
      "ind: 8000, loss: 0.2980993390083313\n",
      "ind: 8500, loss: 0.06660129874944687\n",
      "ind: 9000, loss: 0.07051374018192291\n",
      "ind: 9500, loss: 0.2875252664089203\n"
     ]
    }
   ],
   "source": [
    "l2_loss_pred = []\n",
    "for ind in range(iters):\n",
    "    batch_spikes_data = next(iter(spike_sampler))\n",
    "    x = torch.flatten(batch_spikes_data['fft_spikes'], 1).to(torch.float)\n",
    "    y = batch_spikes_data['n_spikes'].to(torch.float)\n",
    "    y_pred = mlp_net(x)\n",
    "    pred_loss = l2_loss(y, y_pred)\n",
    "    pred_loss.backward()\n",
    "    optim.step()\n",
    "    l2_loss_pred.append(pred_loss.detach().cpu().numpy())\n",
    "    if ind % 500 ==0:\n",
    "        print(f'ind: {ind}, loss: {pred_loss}')\n",
    "l2_loss_pred=np.array(l2_loss_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "85cb7a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11ebc5850>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(l2_loss_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "95be3ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PikesClaseesNet(nn.Module):\n",
    "    def __init__(self,in_size,ch_list, n_classes):\n",
    "        super(PikesClaseesNet, self).__init__()\n",
    "        ch_list =  ch_list + [n_classes]\n",
    "        self.mlp_net = MlpNet(in_ch=in_size,\n",
    "                     ch_list = ch_list,\n",
    "                      out_ch=n_classes,\n",
    "                     deep=len(ch_list),\n",
    "                      multy_coeff=0.5)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        out_net = self.mlp_net(x)\n",
    "        return self.sigmoid (out_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3d5bc353",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_list = [in_size, in_size // 4, in_size // 8, in_size //16, in_size // 32, in_size // 64]\n",
    "# mlp_net = MlpNet(in_ch=in_size,\n",
    "#                  ch_list = ch_list,\n",
    "#                   out_ch=1,\n",
    "#                  deep=len(ch_list),\n",
    "#                   multy_coeff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "053124c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1024, 256, 128, 64, 32, 16], [1024, 256, 128, 64, 32, 16, 7])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_list, ch_list + [n_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "716cd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "pikes_classes_net = PikesClaseesNet(in_size=in_size, ch_list = ch_list, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "96c1f0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpNet(\n",
       "  (fc_layers): BlockList(\n",
       "    (0): FcBlock(\n",
       "      (fc_seq): BlockList(\n",
       "        (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (1): Identity()\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): FcBlock(\n",
       "      (fc_seq): BlockList(\n",
       "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (1): Identity()\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): FcBlock(\n",
       "      (fc_seq): BlockList(\n",
       "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (1): Identity()\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): FcBlock(\n",
       "      (fc_seq): BlockList(\n",
       "        (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (1): Identity()\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): FcBlock(\n",
       "      (fc_seq): BlockList(\n",
       "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "        (1): Identity()\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): FcBlock(\n",
       "      (fc_seq): BlockList(\n",
       "        (0): Linear(in_features=16, out_features=7, bias=True)\n",
       "        (1): Identity()\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pikes_classes_net.mlp_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4a337978",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.flatten(batch_spikes_data['fft_spikes'], 1).to(torch.float)\n",
    "y = batch_spikes_data['n_spikes'].to(torch.long)\n",
    "y_pred = pikes_classes_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9f0e5885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070],\n",
       "        [0.4994, 0.5375, 0.4893, 0.5345, 0.4926, 0.5745, 0.5070]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fc8cf0cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Class values must be smaller than num_classes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-203dffd91cca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Class values must be smaller than num_classes."
     ]
    }
   ],
   "source": [
    "torch.nn.functional.one_hot(y, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cd129d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[6],\n",
       "         [5],\n",
       "         [7],\n",
       "         [2],\n",
       "         [6],\n",
       "         [2],\n",
       "         [6],\n",
       "         [2],\n",
       "         [6],\n",
       "         [3],\n",
       "         [4],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [7]]),\n",
       " 7)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2373d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914477b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
